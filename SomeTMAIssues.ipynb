{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "import os\n",
    "import gc   \n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "\n",
    "\n",
    "combined_df = pd.read_csv('/root/ubc_ocean/alper/models/similar_tmas/similar_images_final_combined.csv')\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, image_paths, batch_size=32, dim=(224, 224), n_channels=3, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.image_paths = image_paths\n",
    "        self.n_channels = n_channels\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.image_paths) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        image_paths_temp = [self.image_paths[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X = self.__data_generation(image_paths_temp)\n",
    "\n",
    "        return X, X\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.image_paths))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, image_paths_temp):\n",
    "        'Generates data containing batch_size samples'\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "\n",
    "        # Generate data\n",
    "        for i, img_path in enumerate(image_paths_temp):\n",
    "            # Store sample\n",
    "            img = load_img(img_path, target_size=self.dim)\n",
    "            X[i,] = img_to_array(img) / 255.0\n",
    "\n",
    "        return X\n",
    "\n",
    "# Parameters\n",
    "params = {'dim': (224, 224),\n",
    "          'batch_size': 32,\n",
    "          'n_channels': 3,\n",
    "          'shuffle': True}\n",
    "\n",
    "# Datasets\n",
    "image_paths = combined_df['Similar_Image_Path'].tolist()  # Assuming this is your dataset\n",
    "\n",
    "# Generators\n",
    "training_generator = DataGenerator(image_paths, **params)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "gc.set_threshold(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Reshape, UpSampling2D\n",
    "from keras.models import Model\n",
    "\n",
    "def build_simple_autoencoder(input_shape=(224, 224, 3)):\n",
    "    # Encoder\n",
    "    input_img = Input(shape=input_shape)\n",
    "    x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    encoded = Dense(64, activation='relu')(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = Dense(56 * 56 * 8, activation='relu')(encoded)\n",
    "    x = Reshape((56, 56, 8))(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "# Build and compile the simpler autoencoder\n",
    "simple_autoencoder = build_simple_autoencoder()\n",
    "simple_autoencoder.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_autoencoder.fit(training_generator, epochs=10, validation_data=training_generator)\n",
    "simple_autoencoder.save('CheckAutoencoderSimple.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Reshape, UpSampling2D, BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "def build_enhanced_autoencoder(input_shape=(224, 224, 3)):\n",
    "    # Encoder\n",
    "    input_img = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    encoded = Dense(128, activation='relu')(x)\n",
    "    # Decoder\n",
    "    x = Dense(14 * 14 * 128, activation='relu')(encoded)  # Измените размер, если необходимо\n",
    "    x = Reshape((14, 14, 128))(x)\n",
    "    x = UpSampling2D((2, 2))(x)  # Увеличиваем до 28x28\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = UpSampling2D((2, 2))(x)  # Увеличиваем до 224x224, если это последний шаг увеличения\n",
    "    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "# Build and compile the autoencoder\n",
    "autoencoder = build_enhanced_autoencoder()\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder.fit(training_generator, epochs=10, validation_data=training_generator)\n",
    "#autoencoder.save('CheckAutoencoder.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from random import sample\n",
    "from PIL import Image  # Import Pillow for image dimension retrieval\n",
    "\n",
    "combined_df = pd.read_csv('/root/ubc_ocean/alper/models/similar_tmas/similar_images_final_combined.csv')\n",
    "random_image_paths = sample(combined_df['Similar_Image_Path'].unique().tolist(), 25)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i, img_path in enumerate(random_image_paths, 1):\n",
    "    img = mpimg.imread(img_path)  # Make sure the img_path is accessible\n",
    "    \n",
    "    # Get image dimensions using Pillow\n",
    "    with Image.open(img_path) as img_pillow:\n",
    "        width, height = img_pillow.size\n",
    "    \n",
    "    plt.subplot(5, 5, i)  # Arrange images in a 5x5 grid\n",
    "    plt.imshow(img)\n",
    "    plt.text(5, 5, f'#{i}', color='black', fontsize=14, weight='bold')  # Adjusted position for number label\n",
    "    plt.text(5, 180, f'{width} x {height}', color='black', fontsize=12)  # Adjusted position for image dimensions\n",
    "    plt.axis('off')  # Hide axis\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "autoencoder = load_model('CheckAutoencoderSimple.h5')\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# Build the encoder model from the existing autoencoder layers\n",
    "encoder_input = autoencoder.input\n",
    "#encoded_output = autoencoder.get_layer('conv2d_21').output  # This is the last layer of the encoder part\n",
    "encoded_output = autoencoder.get_layer('conv2d_5').output\n",
    "\n",
    "\n",
    "# Flatten the output of the encoder to feed into the dense layers\n",
    "flattened = Flatten()(encoded_output)\n",
    "\n",
    "# Add dense layers for classification\n",
    "hidden = Dense(128, activation='relu')(flattened)\n",
    "dropout = Dropout(0.5)(hidden)\n",
    "output = Dense(5, activation='softmax')(dropout)  # num_classes is the number of your target classes\n",
    "\n",
    "# Create a new model for classification\n",
    "classifier_model = Model(inputs=encoder_input, outputs=output)\n",
    "\n",
    "# Compile the model\n",
    "classifier_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print the summary of the new model\n",
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "tma_image_paths = pd.read_csv('/root/ubc_ocean/alper/models/paths/tma_image_paths.csv')\n",
    "train_labels = pd.read_csv('/root/ubc/train.csv')\n",
    "\n",
    "# Extract the image ID from the file path\n",
    "tma_image_paths['image_id'] = tma_image_paths['img_path'].apply(lambda x: os.path.splitext(os.path.basename(x))[0])\n",
    "\n",
    "# Convert the image_id in train_labels to string if it's not already\n",
    "train_labels['image_id'] = train_labels['image_id'].astype(str)\n",
    "\n",
    "# Merge the two DataFrames based on the image_id\n",
    "merged_data = pd.merge(tma_image_paths, train_labels, on='image_id')\n",
    "\n",
    "# Split your data into train, validation, and test sets ensuring at least one sample from each label in the test set\n",
    "grouped = merged_data.groupby('label')\n",
    "test_data = pd.concat([group.sample(1, random_state=42) for name, group in grouped])\n",
    "train_val_data = merged_data.drop(test_data.index)\n",
    "x_train, x_val = train_test_split(train_val_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert these to lists of image paths for training the model\n",
    "train_image_paths = x_train['img_path'].tolist()\n",
    "train_labels = x_train['label'].values\n",
    "\n",
    "val_image_paths = x_val['img_path'].tolist()\n",
    "val_labels = x_val['label'].values\n",
    "\n",
    "test_image_paths = test_data['img_path'].tolist()\n",
    "test_labels = test_data['label'].values\n",
    "\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "# Function to preprocess a single image\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    return np.squeeze(img_array)\n",
    "\n",
    "\n",
    "# Extract features for each set\n",
    "train_features = [preprocess_image(img_path) for img_path in train_image_paths]\n",
    "val_features = [preprocess_image(img_path) for img_path in val_image_paths]\n",
    "test_features = [preprocess_image(img_path) for img_path in test_image_paths]\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list to a NumPy array before normalization\n",
    "train_features_array = np.array(train_features)\n",
    "test_features_array = np.array(test_features)\n",
    "# Normalize the features\n",
    "train_features_normalized = train_features_array / 255.0\n",
    "test_features_normalized = test_features_array / 255.0\n",
    "\n",
    "# Checking the shape and type of the normalized features\n",
    "shape_of_normalized_features = train_features_normalized.shape\n",
    "type_of_normalized_features = train_features_normalized.dtype\n",
    "\n",
    "shape_of_normalized_features_test = test_features_normalized.shape\n",
    "type_of_normalized_features_test = test_features_normalized.dtype\n",
    "\n",
    "\n",
    "# Output the shape and type\n",
    "print(\"Shape of normalized train features:\", shape_of_normalized_features)\n",
    "print(\"Type of normalized train features:\", type_of_normalized_features)\n",
    "\n",
    "\n",
    "# Output the shape and type\n",
    "print(\"Shape of normalized test features:\", shape_of_normalized_features_test)\n",
    "print(\"Type of normalized test features:\", type_of_normalized_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming train_labels is an array of categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "numeric_labels = label_encoder.fit_transform(train_labels)\n",
    "numeric_labels\n",
    "\n",
    "numeric_labels_test = label_encoder.fit_transform(test_labels)\n",
    "numeric_labels_test\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Assuming there are 5 different classes\n",
    "num_classes = 5\n",
    "y_train = to_categorical(numeric_labels, num_classes=num_classes)\n",
    "y_test = to_categorical(numeric_labels_test, num_classes=num_classes)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "history = classifier_model.fit(\n",
    "    train_features_normalized, \n",
    "    y_train, \n",
    "    epochs=50, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2  # Splitting the training data for validation\n",
    ")\n",
    "\n",
    "# Plotting training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left') \n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "test_predictions = classifier_model.predict(test_features_normalized)\n",
    "\n",
    "# The `test_predictions` array will contain the predicted probabilities or labels,\n",
    "# depending on the last layer of your model and the activation function used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "true_labels = np.argmax(y_test, axis=1)  # Only necessary if y_test is one-hot encoded\n",
    "true_labels = np.array(true_labels)\n",
    "predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='macro', zero_division=1)\n",
    "recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1 Score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_test contains the true labels\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "true_labels = np.argmax(y_test, axis=1)  # Only necessary if y_test is one-hot encoded\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
