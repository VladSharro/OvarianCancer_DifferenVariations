{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":45867,"databundleVersionId":6924515,"sourceType":"competition"},{"sourceId":3729,"sourceType":"modelInstanceVersion","modelInstanceId":2656}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-09T12:29:07.817983Z","iopub.execute_input":"2024-02-09T12:29:07.819276Z","iopub.status.idle":"2024-02-09T12:29:07.848245Z","shell.execute_reply.started":"2024-02-09T12:29:07.819176Z","shell.execute_reply":"2024-02-09T12:29:07.847339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torch torchvision torchaudio\n!pip install --upgrade torch torchvision torchaudio\n\n\nimport os\nimport gc\nimport cv2\nimport math\nimport copy\nimport time\nimport random\nimport glob\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.cuda import amp\nimport torchvision\nimport torchvision.transforms as transforms\n\n# Utils\nimport joblib\nfrom tqdm import tqdm\nfrom collections import defaultdict\n\n# Sklearn Imports\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\n\n# For Image Models\nimport timm\n\n# Albumentations for augmentations\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom sklearn.metrics import f1_score\n\n\n# For colored terminal text\nfrom colorama import Fore, Back, Style\nb_ = Fore.BLUE\nsr_ = Style.RESET_ALL\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:07.850098Z","iopub.execute_input":"2024-02-09T12:29:07.850635Z","iopub.status.idle":"2024-02-09T12:29:34.740780Z","shell.execute_reply.started":"2024-02-09T12:29:07.850603Z","shell.execute_reply":"2024-02-09T12:29:34.739022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import timm\n#model = timm.create_model('tf_efficientnet_b0', checkpoint_path='/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b0/1/tf_efficientnet_b0_aa-827b6e33.pth')\n#model.eval()\n\n#import urllib\n#from PIL import Image\n#from timm.data import resolve_data_config\n#from timm.data.transforms_factory import create_transform","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.742523Z","iopub.execute_input":"2024-02-09T12:29:34.742896Z","iopub.status.idle":"2024-02-09T12:29:34.749773Z","shell.execute_reply.started":"2024-02-09T12:29:34.742863Z","shell.execute_reply":"2024-02-09T12:29:34.747936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_f1(preds, labels, is_multiclass=True, average_type='weighted'):\n    preds = preds.cpu().numpy()\n    labels = labels.cpu().numpy()\n    if is_multiclass:\n        # Для многоклассовой классификации\n        return f1_score(labels, preds, average=average_type)\n    else:\n        # Для бинарной классификации\n        return f1_score(labels, preds, average='binary')","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.753093Z","iopub.execute_input":"2024-02-09T12:29:34.753562Z","iopub.status.idle":"2024-02-09T12:29:34.762225Z","shell.execute_reply.started":"2024-02-09T12:29:34.753484Z","shell.execute_reply":"2024-02-09T12:29:34.761004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = '/kaggle/input/UBC-OCEAN'\nTRAIN_DIR = '/kaggle/input/UBC-OCEAN/train_thumbnails'\nTEST_DIR = '/kaggle/input/UBC-OCEAN/test_images'","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.764279Z","iopub.execute_input":"2024-02-09T12:29:34.764694Z","iopub.status.idle":"2024-02-09T12:29:34.772123Z","shell.execute_reply.started":"2024-02-09T12:29:34.764627Z","shell.execute_reply":"2024-02-09T12:29:34.771068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = {\n    \"seed\": 40,\n    \"epochs\": 3,\n    \"img_size\": 512,\n    \"model_name\": \"tf_efficientnet_b0_ns\",\n    \"checkpoint_path\" : \"/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b0/1/tf_efficientnet_b0_aa-827b6e33.pth\",\n    \"num_classes\": 5,\n    \"train_batch_size\": 32,\n    \"valid_batch_size\": 64,\n    \"learning_rate\": 1e-4,\n    \"scheduler\": 'CosineAnnealingLR',\n    \"min_lr\": 1e-6,\n    \"T_max\": 500,\n    \"weight_decay\": 1e-6,\n    \"fold\" : 0,\n    \"n_fold\": 5,\n    \"n_accumulate\": 1,\n    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.773743Z","iopub.execute_input":"2024-02-09T12:29:34.774961Z","iopub.status.idle":"2024-02-09T12:29:34.787004Z","shell.execute_reply.started":"2024-02-09T12:29:34.774909Z","shell.execute_reply":"2024-02-09T12:29:34.785685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport timm\n\nclass CustomModel(nn.Module):\n    def __init__(self, model_name=CONFIG['model_name'], num_classes=CONFIG['num_classes'], pretrained=True):\n        super(CustomModel, self).__init__()\n        # Загружаем предобученную модель из timm\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        \n        # Получаем количество признаков на входе последнего слоя\n        if 'resnet' in model_name or 'efficientnet' in model_name:\n            n_features = self.model.get_classifier().in_features\n        elif 'vit' in model_name or 'deit' in model_name:\n            n_features = self.model.head.in_features\n        else:\n            # Добавьте поддержку других архитектур по необходимости\n            raise NotImplementedError(\"Model architecture not supported yet.\")\n        \n        # Заменяем последний слой модели на новый, с выходом по количеству классов\n        # для задачи классификации\n        if 'resnet' in model_name or 'efficientnet' in model_name:\n            self.model.fc = nn.Linear(n_features, num_classes)\n        elif 'vit' in model_name or 'deit' in model_name:\n            self.model.head = nn.Linear(n_features, num_classes)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.788975Z","iopub.execute_input":"2024-02-09T12:29:34.789953Z","iopub.status.idle":"2024-02-09T12:29:34.800600Z","shell.execute_reply.started":"2024-02-09T12:29:34.789907Z","shell.execute_reply":"2024-02-09T12:29:34.799693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_paths = ROOT_DIR","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.801992Z","iopub.execute_input":"2024-02-09T12:29:34.803047Z","iopub.status.idle":"2024-02-09T12:29:34.816527Z","shell.execute_reply.started":"2024-02-09T12:29:34.803005Z","shell.execute_reply":"2024-02-09T12:29:34.815359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_file_path(image_id):\n    return f\"{TRAIN_DIR}/{image_id}_thumbnail.png\"","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.818991Z","iopub.execute_input":"2024-02-09T12:29:34.819945Z","iopub.status.idle":"2024-02-09T12:29:34.832908Z","shell.execute_reply.started":"2024-02-09T12:29:34.819907Z","shell.execute_reply":"2024-02-09T12:29:34.831907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images = sorted(glob.glob(f\"{TRAIN_DIR}/*.png\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.837152Z","iopub.execute_input":"2024-02-09T12:29:34.837899Z","iopub.status.idle":"2024-02-09T12:29:34.848440Z","shell.execute_reply.started":"2024-02-09T12:29:34.837865Z","shell.execute_reply":"2024-02-09T12:29:34.847133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(f\"{ROOT_DIR}/train.csv\")\ndf['file_path'] = df['image_id'].apply(get_train_file_path)\ndf = df[ df[\"file_path\"].isin(train_images) ].reset_index(drop=True)\ndf","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.850897Z","iopub.execute_input":"2024-02-09T12:29:34.852023Z","iopub.status.idle":"2024-02-09T12:29:34.888366Z","shell.execute_reply.started":"2024-02-09T12:29:34.851974Z","shell.execute_reply":"2024-02-09T12:29:34.887011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, image_paths, targets, transform=None):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        image_path = self.image_paths[index]\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        \n        target = self.targets[index]\n        return image, target\n    \n    \n    \ntrain_transforms = A.Compose([\n    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2(),\n])\n\nvalid_transforms = A.Compose([\n    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n    ToTensorV2(),\n])","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.890434Z","iopub.execute_input":"2024-02-09T12:29:34.891133Z","iopub.status.idle":"2024-02-09T12:29:34.902189Z","shell.execute_reply.started":"2024-02-09T12:29:34.891087Z","shell.execute_reply":"2024-02-09T12:29:34.900980Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_dataset = CustomDataset(TRAIN_DIR, train_targets, transform=train_transforms)\n#valid_dataset = CustomDataset(ROOT_DIR, valid_targets, transform=valid_transforms)\n\n#train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], shuffle=True)\n#valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.903557Z","iopub.execute_input":"2024-02-09T12:29:34.903902Z","iopub.status.idle":"2024-02-09T12:29:34.915440Z","shell.execute_reply.started":"2024-02-09T12:29:34.903874Z","shell.execute_reply":"2024-02-09T12:29:34.914515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\ndf['label'] = encoder.fit_transform(df['label'])\n\nwith open(\"label_encoder.pkl\", \"wb\") as fp:\n    joblib.dump(encoder, fp)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.916647Z","iopub.execute_input":"2024-02-09T12:29:34.917697Z","iopub.status.idle":"2024-02-09T12:29:34.929321Z","shell.execute_reply.started":"2024-02-09T12:29:34.917635Z","shell.execute_reply":"2024-02-09T12:29:34.928394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG['T_max'] = df.shape[0] * (CONFIG[\"n_fold\"]-1) * CONFIG['epochs'] // CONFIG['train_batch_size'] // CONFIG[\"n_fold\"]\nCONFIG['T_max']","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.931178Z","iopub.execute_input":"2024-02-09T12:29:34.931910Z","iopub.status.idle":"2024-02-09T12:29:34.942395Z","shell.execute_reply.started":"2024-02-09T12:29:34.931867Z","shell.execute_reply":"2024-02-09T12:29:34.941266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CONFIG = {\n#    \"seed\": 42,\n#    \"epochs\": 20,\n#    \"img_size\": 512,\n#    \"model_name\": \"tf_efficientnet_b0_ns\",\n#    \"checkpoint_path\" : \"/kaggle/input/tf-efficientnet/pytorch/tf-efficientnet-b0/1/tf_efficientnet_b0_aa-827b6e33.pth\",\n#    \"num_classes\": 8,\n#    \"train_batch_size\": 32,\n#    \"valid_batch_size\": 64,\n#    \"learning_rate\": 1e-4,\n#    \"scheduler\": 'CosineAnnealingLR',\n#    \"min_lr\": 1e-6,\n#    \"T_max\": 500,\n#    \"weight_decay\": 1e-6,\n#    \"fold\" : 0,\n#    \"n_fold\": 5,\n#    \"n_accumulate\": 1,\n#    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n#}","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.945897Z","iopub.execute_input":"2024-02-09T12:29:34.946751Z","iopub.status.idle":"2024-02-09T12:29:34.953051Z","shell.execute_reply.started":"2024-02-09T12:29:34.946697Z","shell.execute_reply":"2024-02-09T12:29:34.951638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed=40):\n\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    # When running on the CuDNN backend, two further options must be set\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    # Set a fixed value for the hash seed\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed(CONFIG['seed'])","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.955030Z","iopub.execute_input":"2024-02-09T12:29:34.955758Z","iopub.status.idle":"2024-02-09T12:29:34.971354Z","shell.execute_reply.started":"2024-02-09T12:29:34.955716Z","shell.execute_reply":"2024-02-09T12:29:34.970110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=CONFIG['n_fold'])\n\nfor fold, ( _, val_) in enumerate(skf.split(X=df, y=df.label)):\n      df.loc[val_ , \"kfold\"] = int(fold)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:34.975641Z","iopub.execute_input":"2024-02-09T12:29:34.976056Z","iopub.status.idle":"2024-02-09T12:29:34.990214Z","shell.execute_reply.started":"2024-02-09T12:29:34.976024Z","shell.execute_reply":"2024-02-09T12:29:34.988854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, image_paths, targets, transform=None):\n        self.image_paths = image_paths\n        self.targets = targets\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        image_path = self.image_paths[index]\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        \n        target = self.targets[index]\n        return image, target","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.002648Z","iopub.execute_input":"2024-02-09T12:29:35.003055Z","iopub.status.idle":"2024-02-09T12:29:35.013133Z","shell.execute_reply.started":"2024-02-09T12:29:35.003022Z","shell.execute_reply":"2024-02-09T12:29:35.011903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transforms = A.Compose([\n    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n    ToTensorV2(),\n])\n\nvalid_transforms = A.Compose([\n    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n    ToTensorV2(),\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.016989Z","iopub.execute_input":"2024-02-09T12:29:35.017731Z","iopub.status.idle":"2024-02-09T12:29:35.029742Z","shell.execute_reply.started":"2024-02-09T12:29:35.017693Z","shell.execute_reply":"2024-02-09T12:29:35.028633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_transforms = {\n    \"train\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.ShiftScaleRotate(shift_limit=0.1, \n                           scale_limit=0.15, \n                           rotate_limit=60, \n                           p=0.5),\n        A.HueSaturationValue(\n                hue_shift_limit=0.2, \n                sat_shift_limit=0.2, \n                val_shift_limit=0.2, \n                p=0.5\n            ),\n        A.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5\n            ),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.),\n    \n    \"valid\": A.Compose([\n        A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n        A.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n        ToTensorV2()], p=1.)\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.031341Z","iopub.execute_input":"2024-02-09T12:29:35.031741Z","iopub.status.idle":"2024-02-09T12:29:35.041791Z","shell.execute_reply.started":"2024-02-09T12:29:35.031704Z","shell.execute_reply":"2024-02-09T12:29:35.040713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM, self).__init__()\n        self.p = nn.Parameter(torch.ones(1)*p)\n        self.eps = eps\n\n    def forward(self, x):\n        return self.gem(x, p=self.p, eps=self.eps)\n        \n    def gem(self, x, p=3, eps=1e-6):\n        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n        \n    def __repr__(self):\n        return self.__class__.__name__ + \\\n                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n                ', ' + 'eps=' + str(self.eps) + ')'","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.043309Z","iopub.execute_input":"2024-02-09T12:29:35.043692Z","iopub.status.idle":"2024-02-09T12:29:35.058123Z","shell.execute_reply.started":"2024-02-09T12:29:35.043629Z","shell.execute_reply":"2024-02-09T12:29:35.056978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score\n\ndef train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n    model.train()\n    running_loss = 0.0\n    correct_predictions = torch.tensor(0, device=device)  # Используем тензор для подсчета\n    dataset_size = 0\n    all_preds = []\n    all_labels = []\n\n    for step, data in tqdm(enumerate(dataloader), total=len(dataloader)):\n        images = data['image'].to(device, dtype=torch.float)\n        labels = data['label'].to(device, dtype=torch.long)\n        batch_size = images.size(0)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()  # Обновление после каждого батча\n\n        running_loss += (loss.item() * batch_size)\n        correct_predictions += (predicted == labels).sum()\n        dataset_size += batch_size\n        \n        all_preds.extend(predicted.view(-1).cpu().numpy())\n        all_labels.extend(labels.view(-1).cpu().numpy())\n\n    epoch_loss = running_loss / dataset_size\n    epoch_acc = correct_predictions.double() / dataset_size\n    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n    epoch_precision = precision_score(all_labels, all_preds, average='macro')\n    epoch_recall = recall_score(all_labels, all_preds, average='macro')\n\n    return epoch_loss, epoch_acc.item(), epoch_f1, epoch_precision, epoch_recall\n\n\n\n\n\ndef valid_one_epoch(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct_predictions = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for data in tqdm(dataloader):\n            inputs = data['image'].to(device)\n            labels = data['label'].to(device)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            running_loss += loss.item() * inputs.size(0)\n            _, preds = torch.max(outputs, 1)\n            correct_predictions += torch.sum(preds == labels.data)\n            \n            all_preds.extend(preds.view(-1).cpu().numpy())\n            all_labels.extend(labels.data.view(-1).cpu().numpy())\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = correct_predictions.double() / len(dataloader.dataset)\n    epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n    epoch_precision = precision_score(all_labels, all_preds, average='weighted')\n    epoch_recall = recall_score(all_labels, all_preds, average='weighted')\n\n    print(f'Validation Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, F1: {epoch_f1:.4f}, Precision: {epoch_precision:.4f}, Recall: {epoch_recall:.4f}')\n\n    return epoch_loss, epoch_acc, epoch_f1, epoch_precision, epoch_recall\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.060050Z","iopub.execute_input":"2024-02-09T12:29:35.060510Z","iopub.status.idle":"2024-02-09T12:29:35.077280Z","shell.execute_reply.started":"2024-02-09T12:29:35.060469Z","shell.execute_reply":"2024-02-09T12:29:35.076260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = CustomModel().to(CONFIG['device'])\n#criterion = nn.CrossEntropyLoss()\n#optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'])\n\n\n#train_transforms = A.Compose([\n#    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n#    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n#    ToTensorV2(),\n#])\n\n#valid_transforms = A.Compose([\n#    A.Resize(CONFIG['img_size'], CONFIG['img_size']),\n#    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n#    ToTensorV2(),\n#])","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.078643Z","iopub.execute_input":"2024-02-09T12:29:35.079335Z","iopub.status.idle":"2024-02-09T12:29:35.091127Z","shell.execute_reply.started":"2024-02-09T12:29:35.079297Z","shell.execute_reply":"2024-02-09T12:29:35.090091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for epoch in range(CONFIG['epochs']):\n#    print(f'Epoch {epoch+1}/{CONFIG[\"epochs\"]}')\n#    train_one_epoch(model, train_loader, criterion, optimizer, CONFIG['device'])\n#    valid_one_epoch(model, valid_loader, criterion, CONFIG['device'])\n#    print('-' * 10)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.092748Z","iopub.execute_input":"2024-02-09T12:29:35.093103Z","iopub.status.idle":"2024-02-09T12:29:35.105505Z","shell.execute_reply.started":"2024-02-09T12:29:35.093075Z","shell.execute_reply":"2024-02-09T12:29:35.104458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UBCModel(nn.Module):\n    def __init__(self, model_name, num_classes, pretrained=True, checkpoint_path=None):\n        super(UBCModel, self).__init__()\n        self.model = timm.create_model(model_name, pretrained=pretrained, checkpoint_path=checkpoint_path)\n\n        in_features = self.model.classifier.in_features\n        self.model.classifier = nn.Identity()\n        self.model.global_pool = nn.Identity()\n        self.pooling = GeM()\n        self.linear = nn.Linear(in_features, num_classes)\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, images):\n        features = self.model(images)\n        pooled_features = self.pooling(features).flatten(1)\n        output = self.linear(pooled_features)\n        return output\n\n    \nmodel = UBCModel(CONFIG['model_name'], CONFIG['num_classes'], checkpoint_path=CONFIG['checkpoint_path'])\nmodel.to(CONFIG['device']);","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.121421Z","iopub.execute_input":"2024-02-09T12:29:35.122456Z","iopub.status.idle":"2024-02-09T12:29:35.553809Z","shell.execute_reply.started":"2024-02-09T12:29:35.122422Z","shell.execute_reply":"2024-02-09T12:29:35.552610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def criterion(outputs, labels):\n    return nn.CrossEntropyLoss()(outputs, labels)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.556462Z","iopub.execute_input":"2024-02-09T12:29:35.557011Z","iopub.status.idle":"2024-02-09T12:29:35.563121Z","shell.execute_reply.started":"2024-02-09T12:29:35.556968Z","shell.execute_reply":"2024-02-09T12:29:35.561541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch):\n#    model.train()\n#    running_loss = 0.0\n#    correct_predictions = 0\n#    all_preds = []\n#    all_targets = []\n    \n#    for inputs, labels in dataloader:\n#        inputs = inputs.to(device)\n#        labels = labels.to(device)\n#        \n#        optimizer.zero_grad()\n#        \n#        outputs = model(inputs)\n#        loss = criterion(outputs, labels)\n#        loss.backward()\n#        optimizer.step()\n        \n#        running_loss += loss.item() * inputs.size(0)\n#        _, preds = torch.max(outputs, 1)\n#        correct_predictions += torch.sum(preds == labels)\n        \n        # Collect all predictions and labels for F1 score calculation\n#        all_preds.append(preds)\n#        all_targets.append(labels)\n        \n    # Convert all collected predictions and labels to a single tensor\n#    all_preds = torch.cat(all_preds).cpu()\n#    all_targets = torch.cat(all_targets).cpu()\n    \n    # Calculate accuracy\n#    epoch_acc = correct_predictions.double() / len(dataloader.dataset)\n    \n    # Calculate F1 score using sklearn's f1_score function\n#    epoch_f1 = f1_score(all_targets.numpy(), all_preds.numpy(), average='macro')\n    \n#    epoch_loss = running_loss / len(dataloader.dataset)\n    \n#    return epoch_loss, epoch_acc, epoch_f1\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.565008Z","iopub.execute_input":"2024-02-09T12:29:35.565511Z","iopub.status.idle":"2024-02-09T12:29:35.578622Z","shell.execute_reply.started":"2024-02-09T12:29:35.565468Z","shell.execute_reply":"2024-02-09T12:29:35.576699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef valid_one_epoch(model, dataloader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct_predictions = 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for data in tqdm(dataloader):\n            inputs = data['image'].to(device, dtype=torch.float)\n            labels = data['label'].to(device, dtype=torch.long)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            running_loss += loss.item() * inputs.size(0)\n            _, preds = torch.max(outputs, 1)\n            correct_predictions += torch.sum(preds == labels.data)\n            \n            all_preds.extend(preds.view(-1).cpu().numpy())\n            all_labels.extend(labels.view(-1).cpu().numpy())\n\n    epoch_loss = running_loss / len(dataloader.dataset)\n    epoch_acc = correct_predictions.double() / len(dataloader.dataset)\n    epoch_f1 = f1_score(all_labels, all_preds, average='macro')\n    epoch_precision = precision_score(all_labels, all_preds, average='macro')\n    epoch_recall = recall_score(all_labels, all_preds, average='macro')\n\n    print(f'Validation Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, F1: {epoch_f1:.4f}, Precision: {epoch_precision:.4f}, Recall: {epoch_recall:.4f}')\n\n    return epoch_loss, epoch_acc, epoch_f1, epoch_precision, epoch_recall","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.580577Z","iopub.execute_input":"2024-02-09T12:29:35.581043Z","iopub.status.idle":"2024-02-09T12:29:35.594791Z","shell.execute_reply.started":"2024-02-09T12:29:35.581008Z","shell.execute_reply":"2024-02-09T12:29:35.593489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_training(model, optimizer, scheduler, device, num_epochs):\n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n    \n    start = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_epoch_acc = -np.inf\n    history = defaultdict(list)\n    \n    for epoch in range(1, num_epochs + 1): \n        gc.collect()\n        train_epoch_loss, train_epoch_acc, train_epoch_f1, train_epoch_precision, train_epoch_recall = train_one_epoch(model, optimizer, \n                                                                            scheduler, \n                                                                            dataloader=train_loader, \n                                                                            device=CONFIG['device'], epoch=epoch)\n\n\n        \n        val_epoch_loss, val_epoch_acc, val_epoch_f1, val_epoch_precision, val_epoch_recall = valid_one_epoch(model, valid_loader, criterion, \n                                                                  CONFIG['device'])\n                                                                 #epoch=epoch)\n        \n        #train_loss, train_acc, train_f1 = train_one_epoch(...)\n        #valid_loss, valid_acc, valid_f1 = valid_one_epoch(...)\n\n        #history['Train F1'].append(train_f1)\n        #history['Valid F1'].append(valid_f1)\n    \n        #history['Train Loss'].append(train_epoch_loss)\n        #history['Valid Loss'].append(val_epoch_loss)\n        #history['Train Accuracy'].append(train_epoch_acc)\n        #history['Valid Accuracy'].append(val_epoch_acc)\n        \n        history['Train Loss'].append(train_epoch_loss)\n        history['Train Accuracy'].append(train_epoch_acc)\n        history['Train F1'].append(train_epoch_f1)\n        history['Valid Loss'].append(val_epoch_loss)\n        history['Valid Accuracy'].append(val_epoch_acc)\n        history['Valid F1'].append(val_epoch_f1)\n        \n        history['Train Precision'].append(train_epoch_precision)\n        history['Train Recall'].append(train_epoch_recall)\n        history['Valid Precision'].append(val_epoch_precision)\n        history['Valid Recall'].append(val_epoch_recall)\n\n\n        history['lr'].append( scheduler.get_lr()[0] )\n        \n        # deep copy the model\n        if best_epoch_acc <= val_epoch_acc:\n            print(f\"{b_}Validation Accuracy Improved ({best_epoch_acc} ---> {val_epoch_acc})\")\n            best_epoch_acc = val_epoch_acc\n            best_model_wts = copy.deepcopy(model.state_dict())\n            PATH = \"Acc{:.2f}_Loss{:.4f}_epoch{:.0f}.bin\".format(best_epoch_acc, val_epoch_loss, epoch)\n            torch.save(model.state_dict(), PATH)\n            # Save a model file from the current directory\n            print(f\"Model Saved{sr_}\")\n            \n        print()\n    \n    end = time.time()\n    time_elapsed = end - start\n    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n    print(\"Best Accuracy: {:.4f}\".format(best_epoch_acc))\n    \n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    \n    return model, history","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.596328Z","iopub.execute_input":"2024-02-09T12:29:35.596695Z","iopub.status.idle":"2024-02-09T12:29:35.612192Z","shell.execute_reply.started":"2024-02-09T12:29:35.596639Z","shell.execute_reply":"2024-02-09T12:29:35.610880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fetch_scheduler(optimizer):\n    if CONFIG['scheduler'] == 'CosineAnnealingLR':\n        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=CONFIG['T_max'], \n                                                   eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == 'CosineAnnealingWarmRestarts':\n        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=CONFIG['T_0'], \n                                                             eta_min=CONFIG['min_lr'])\n    elif CONFIG['scheduler'] == None:\n        return None\n        \n    return scheduler","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.613799Z","iopub.execute_input":"2024-02-09T12:29:35.614158Z","iopub.status.idle":"2024-02-09T12:29:35.629146Z","shell.execute_reply.started":"2024-02-09T12:29:35.614123Z","shell.execute_reply":"2024-02-09T12:29:35.628013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UBCDataset(Dataset):\n    def __init__(self, df, transforms=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.labels = df['label'].values\n        self.transforms = transforms\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        img_path = self.file_names[index]\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        label = self.labels[index]\n        \n        if self.transforms:\n            img = self.transforms(image=img)[\"image\"]\n            \n        return {\n            'image': img,\n            'label': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.630723Z","iopub.execute_input":"2024-02-09T12:29:35.631181Z","iopub.status.idle":"2024-02-09T12:29:35.643348Z","shell.execute_reply.started":"2024-02-09T12:29:35.631139Z","shell.execute_reply":"2024-02-09T12:29:35.642157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_loaders(df, fold):\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n    df_valid = df[df.kfold == fold].reset_index(drop=True)\n\n    train_dataset = UBCDataset(df_train, transforms=data_transforms[\"train\"])\n    valid_dataset = UBCDataset(df_valid, transforms=data_transforms[\"valid\"])\n\n    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], \n                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], \n                              num_workers=2, shuffle=False, pin_memory=True)\n\n    return train_loader, valid_loader\n","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.645568Z","iopub.execute_input":"2024-02-09T12:29:35.645982Z","iopub.status.idle":"2024-02-09T12:29:35.655315Z","shell.execute_reply.started":"2024-02-09T12:29:35.645943Z","shell.execute_reply":"2024-02-09T12:29:35.653823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader, valid_loader = prepare_loaders(df, fold=CONFIG[\"fold\"])\noptimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], \n                       weight_decay=CONFIG['weight_decay'])\nscheduler = fetch_scheduler(optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.657347Z","iopub.execute_input":"2024-02-09T12:29:35.658147Z","iopub.status.idle":"2024-02-09T12:29:35.671474Z","shell.execute_reply.started":"2024-02-09T12:29:35.658113Z","shell.execute_reply":"2024-02-09T12:29:35.670448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, history = run_training(model, optimizer, scheduler, device=CONFIG['device'], num_epochs=CONFIG['epochs'])","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:29:35.686041Z","iopub.execute_input":"2024-02-09T12:29:35.686599Z","iopub.status.idle":"2024-02-09T12:40:54.824808Z","shell.execute_reply.started":"2024-02-09T12:29:35.686566Z","shell.execute_reply":"2024-02-09T12:40:54.819934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = pd.DataFrame.from_dict(history)\nhistory.to_csv(\"history.csv\", index=False)\nhistory.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:40:54.829363Z","iopub.status.idle":"2024-02-09T12:40:54.831591Z","shell.execute_reply.started":"2024-02-09T12:40:54.830549Z","shell.execute_reply":"2024-02-09T12:40:54.830648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot( range(history.shape[0]), history[\"Train Loss\"].values, label=\"Train Loss\")\nplt.plot( range(history.shape[0]), history[\"Valid Loss\"].values, label=\"Valid Loss\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"Loss\")\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:40:54.839139Z","iopub.status.idle":"2024-02-09T12:40:54.841467Z","shell.execute_reply.started":"2024-02-09T12:40:54.840144Z","shell.execute_reply":"2024-02-09T12:40:54.840249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot( range(history.shape[0]), history[\"Train Accuracy\"].values, label=\"Train Accuracy\")\nplt.plot( range(history.shape[0]), history[\"Valid Accuracy\"].values, label=\"Valid Accuracy\")\nplt.xlabel(\"epochs\")\nplt.ylabel(\"Accuracy\")\nplt.grid()\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-09T12:40:54.845826Z","iopub.status.idle":"2024-02-09T12:40:54.847183Z","shell.execute_reply.started":"2024-02-09T12:40:54.846731Z","shell.execute_reply":"2024-02-09T12:40:54.846812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_metrics = {\n    'Best Valid F1': history['Valid F1'][best_f1_index],\n    'Corresponding Valid Accuracy': history['Valid Accuracy'][best_f1_index],\n    'Corresponding Valid Precision': history['Valid Precision'][best_f1_index],\n    'Corresponding Valid Recall': history['Valid Recall'][best_f1_index]\n}\n\nbest_metrics","metadata":{},"execution_count":null,"outputs":[]}]}